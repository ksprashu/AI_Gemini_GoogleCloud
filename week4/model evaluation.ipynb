{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899227e7-739e-49a2-84a8-3bdb2396628f",
   "metadata": {},
   "source": [
    "# Model Evaluation using Vertex AI\n",
    "\n",
    "In this notebook, we will compare the responses of 3 models that we are using to build our travel advisor chatbot. \n",
    "\n",
    "* Model #1 - Stock Gemini 1.5 Flash 002 model\n",
    "* Model #2 - Fine-tuned Gemini 1.5 Flash, tuned with sample responses generated by Gemini\n",
    "* Model #3 - Gemma2 9b instruction-tuned model\n",
    "\n",
    "## Steps Performed\n",
    "\n",
    "Before getting to the evaluation, the following steps were performed. \n",
    "\n",
    "### 1) Generate sample queries / prompts\n",
    "We used `Gemini 1.5 Pro` to generate a few arbitrary questions related to travel. We asked the model to don various personas from curious minds, to annoyed ones and ask travel related questions in the style of that persona. \n",
    "\n",
    "This data is stored in `eval_queries.json`. \n",
    "\n",
    "### 2) Generate reponses using each model\n",
    "We then read the prompts generated previously and fed it into each of the model above and saved the response that we got. So for each of the questions asked, we have the responses generated by each of the models. We can use this to do an evaluation - either a point-wise evaluation or a pair-wise comparison. \n",
    "\n",
    "The files are present in `gemini_responses.json`, `gemma_responses.json`, `tuned_responses.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137c7e4-bc51-427a-8d87-7ac910737e8f",
   "metadata": {},
   "source": [
    "## Let's get some data from the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2083c0-10ec-4401-89d4-f0ed86de5259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 57 records\n"
     ]
    }
   ],
   "source": [
    "# How many prompts are present?\n",
    "\n",
    "import json\n",
    "with open('eval_queries.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f'there are {len(data)} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c99ee8b-c9ea-4f28-9096-1e63c2096071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg length of responses in gemini_responses.json is 553.98\n",
      "avg length of responses in gemma_responses.json is 386.75\n",
      "avg length of responses in tuned_responses.json is 170.12\n"
     ]
    }
   ],
   "source": [
    "# Let's check the average length of the responses of each model\n",
    "\n",
    "def print_avg_len(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        prompts = json.load(f)\n",
    "\n",
    "    responses = [prompt['response'] for prompt in prompts]\n",
    "    avg_len_resp = sum(len(s) for s in responses) / len(responses)\n",
    "    print(f'avg length of responses in {filename} is {avg_len_resp:.2f}')\n",
    "\n",
    "print_avg_len('gemini_responses.json')\n",
    "print_avg_len('gemma_responses.json')\n",
    "print_avg_len('tuned_responses.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b735217-cfc5-40dd-a07e-67d0dfe00c73",
   "metadata": {},
   "source": [
    "## Let's do a pointwise evaluation of the responses based on certain criteria\n",
    "\n",
    "1. We want to ensure that the response actually answered the question and didn't give a vague answer or ask a follow-up\n",
    "2. We want to ensure the response is easy to read and friendly\n",
    "3. We want to ensure the response is fun and has emojis and smileys\n",
    "\n",
    "_Note: Ensure we are authenticated with Google Cloud and are using ADC_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ebcff71-4040-49ab-b13d-390d8de270db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (1.71.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (5.28.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (3.26.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (1.13.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.9.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ksprashanth/code/devrel/L200_AI_Challenge/env/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "# install necessary packages\n",
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd29bdd3-df7f-4c04-bc5c-cd3e39756b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import json\n",
    "import dotenv\n",
    "\n",
    "import vertexai\n",
    "from vertexai.evaluation import EvalTask, PointwiseMetric, PointwiseMetricPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f0f875-6aa8-49d1-a8b5-803b9725a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env vars\n",
    "dotenv.load_dotenv()\n",
    "project_id = os.environ.get(\"PROJECT_ID\")\n",
    "location = os.environ.get(\"REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c3eb4fa-76f7-412a-ad26-aeb1a0c47e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init vertex ai\n",
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474b044-1be5-48f9-8f6e-3835a29f5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PointWise metric for the responses\n",
    "\n",
    "travel_response_quality = PointwiseMetric(\n",
    "    metric=\"travel_response_quality\",\n",
    "    metric_prompt_template=PointwiseMetricPromptTemplate(\n",
    "        criteria={\n",
    "            \"fluency\": (\n",
    "                \"Sentences flow smoothly and are easy to read, avoiding awkward\"\n",
    "                \" phrasing or run-on sentences. Ideas and sentences connect\"\n",
    "                \" logically, using transitions effectively where needed.\"\n",
    "            ),\n",
    "            \"entertaining\": (\n",
    "                \"Short, amusing text that incorporates emojis, exclamations and\"\n",
    "                \" questions to convey quick and spontaneous communication and\"\n",
    "                \" diversion.\"\n",
    "            ),\n",
    "        },\n",
    "        rating_rubric={\n",
    "            \"1\": \"The response performs well on both criteria.\",\n",
    "            \"0\": \"The response is somewhat aligned with both criteria\",\n",
    "            \"-1\": \"The response falls short on both criteria\",\n",
    "        },\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
